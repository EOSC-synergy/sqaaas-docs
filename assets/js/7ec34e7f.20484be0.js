"use strict";(self.webpackChunkdoc=self.webpackChunkdoc||[]).push([[99],{3905:function(e,t,a){a.d(t,{Zo:function(){return d},kt:function(){return p}});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function s(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=n.createContext({}),c=function(e){var t=n.useContext(l),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},d=function(e){var t=c(e.components);return n.createElement(l.Provider,{value:t},e.children)},h={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),u=c(a),p=r,m=u["".concat(l,".").concat(p)]||u[p]||h[p]||i;return a?n.createElement(m,o(o({ref:t},d),{},{components:a})):n.createElement(m,o({ref:t},d))}));function p(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=a.length,o=new Array(i);o[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:r,o[1]=s;for(var c=2;c<i;c++)o[c]=a[c];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},1410:function(e,t,a){a.r(t),a.d(t,{contentTitle:function(){return l},default:function(){return u},frontMatter:function(){return s},metadata:function(){return c},toc:function(){return d}});var n=a(7462),r=a(3366),i=(a(7294),a(3905)),o=["components"],s={title:"Analysing the results"},l=void 0,c={unversionedId:"quality_assessment_and_awarding/report",id:"quality_assessment_and_awarding/report",isDocsHomePage:!1,title:"Analysing the results",description:"The quality report",source:"@site/docs/quality_assessment_and_awarding/report.md",sourceDirName:"quality_assessment_and_awarding",slug:"/quality_assessment_and_awarding/report",permalink:"/quality_assessment_and_awarding/report",version:"current",frontMatter:{title:"Analysing the results"},sidebar:"tutorialSidebar",previous:{title:"Triggering the Assessment",permalink:"/quality_assessment_and_awarding/operation"},next:{title:"Sharing the badges",permalink:"/quality_assessment_and_awarding/share"}},d=[{value:"The quality report",id:"the-quality-report",children:[{value:"Awarding through Badges",id:"awarding-through-badges",children:[]}]},{value:"The FAIR data case",id:"the-fair-data-case",children:[]}],h={toc:d};function u(e){var t=e.components,a=(0,r.Z)(e,o);return(0,i.kt)("wrapper",(0,n.Z)({},h,a,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h2",{id:"the-quality-report"},"The quality report"),(0,i.kt)("p",null,"The results obtained by the QAA module highlight the achievements that\ncharacterize a given code repository, and point developers or code owners to\nthose specific parts where quality can be improved. Thus, the ultimate goal is\nto increase the overall quality of the code so that the software product takes\ncredit."),(0,i.kt)("p",null,"The results view shows a report detailing the validity of the criteria covered\nduring the assessment. This validity is estimated on the basis of the results\nand criticality provided by the individual subcriteria. This means that only\nthe subcriteria with the highest level of criticality is considered for the\ncriterion's overall success."),(0,i.kt)("p",{align:"center"},(0,i.kt)("img",{src:"/img/criterion_results.png"})),(0,i.kt)("div",{className:"admonition admonition-note alert alert--secondary"},(0,i.kt)("div",{parentName:"div",className:"admonition-heading"},(0,i.kt)("h5",{parentName:"div"},(0,i.kt)("span",{parentName:"h5",className:"admonition-icon"},(0,i.kt)("svg",{parentName:"span",xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"},(0,i.kt)("path",{parentName:"svg",fillRule:"evenodd",d:"M6.3 5.69a.942.942 0 0 1-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 0 1-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"}))),"note")),(0,i.kt)("div",{parentName:"div",className:"admonition-content"},(0,i.kt)("p",{parentName:"div"},"The codes that identify the subcriteria are aligned, as stated throughout the\ndocs, with the ",(0,i.kt)("a",{parentName:"p",href:"https://indigo-dc.github.io/sqa-baseline/"},"A set of Common Software Quality Assurance Baseline Criteria\nfor Research Projects")," document."))),(0,i.kt)("h3",{id:"awarding-through-badges"},"Awarding through Badges"),(0,i.kt)("p",null,"Reporting is complemented with awarding when the software being analysed\nreaches a minimum level of quality. This is based on the fact that, similarly\nto the subcriteria covered above, not all the criteria have the same level of\nimportance. We have previously established those levels in the\n",(0,i.kt)("a",{parentName:"p",href:"/quality_assessment_and_awarding/synergy_badging_approach"},"Badging in EOSC-Synergy"),"."),(0,i.kt)("p",null,"Whenever the assessed code repository has reached any of the required levels\nof quality, a digital badge will be displayed on top of the report as shown\nin the next image:"),(0,i.kt)("p",{align:"center"},(0,i.kt)("img",{src:"/img/award.png"})),(0,i.kt)("h2",{id:"the-fair-data-case"},"The FAIR data case"),(0,i.kt)("p",null,"The quality indicators that assess the compliance of data with the FAIR\nprinciples are those defined in the\n",(0,i.kt)("a",{parentName:"p",href:"https://doi.org/10.15497/rda00050"},"FAIR Maturity Model")," specification. The\nSQAaaS relies on the ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/EOSC-synergy/FAIR_eva"},"FAIR EVA"),"\ntool to compile and show this information in a similar fashion as the reports\nfor source code and services. Consequently, the report (see example below)\nbuilds on the results of this tool to add:"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Specific ",(0,i.kt)("em",{parentName:"li"},"hints")," that help to cover an unsuccessful FAIR quality indicator"),(0,i.kt)("li",{parentName:"ul"},"A digital ",(0,i.kt)("em",{parentName:"li"},"badge")," that categorizes the overall FAIRness of the analysed\ndataset, which provides a means to establish a minimum set of criteria (through\nthe lower level badge) and additional higher levels of FAIR compliance.")),(0,i.kt)("p",{align:"center"},(0,i.kt)("img",{src:"/img/fair_report.png"})))}u.isMDXComponent=!0}}]);